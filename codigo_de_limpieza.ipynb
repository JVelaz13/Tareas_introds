{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f630604",
   "metadata": {},
   "source": [
    "# Primer paso.\n",
    "Primero debemos importar la libreria pandas e importar la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f1eebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>name</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_population_25_over</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_home_value</th>\n",
       "      <th>educational_attainment</th>\n",
       "      <th>white_alone</th>\n",
       "      <th>black_alone</th>\n",
       "      <th>native_alone</th>\n",
       "      <th>asian_alone</th>\n",
       "      <th>native_hawaiian_pacific_islander</th>\n",
       "      <th>some_other_race_alone</th>\n",
       "      <th>two_or_more</th>\n",
       "      <th>hispanic_or_latino</th>\n",
       "      <th>city</th>\n",
       "      <th>metro_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.100101e+10</td>\n",
       "      <td>Census Tract 75.03, District of Columbia, Dist...</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>26250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Census Tract 76.01, District of Columbia, Dist...</td>\n",
       "      <td>4855.0</td>\n",
       "      <td>3463.0</td>\n",
       "      <td>34840.0</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>4292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.100101e+10</td>\n",
       "      <td>Census Tract 77.09, District of Columbia, Dist...</td>\n",
       "      <td>2524.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>33750.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.100101e+10</td>\n",
       "      <td>Census Tract 95.08, District of Columbia, Dist...</td>\n",
       "      <td>3691.0</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>56404.0</td>\n",
       "      <td>356600.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.100101e+10</td>\n",
       "      <td>Census Tract 99.04, District of Columbia, Dist...</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>30728.0</td>\n",
       "      <td>298600.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          geoid                                               name  \\\n",
       "0  1.100101e+10  Census Tract 75.03, District of Columbia, Dist...   \n",
       "1           NaN  Census Tract 76.01, District of Columbia, Dist...   \n",
       "2  1.100101e+10  Census Tract 77.09, District of Columbia, Dist...   \n",
       "3  1.100101e+10  Census Tract 95.08, District of Columbia, Dist...   \n",
       "4  1.100101e+10  Census Tract 99.04, District of Columbia, Dist...   \n",
       "\n",
       "   total_population  total_population_25_over median_income median_home_value  \\\n",
       "0            2454.0                    1425.0       26250.0               NaN   \n",
       "1            4855.0                    3463.0       34840.0          255000.0   \n",
       "2            2524.0                    1817.0       33750.0          250000.0   \n",
       "3            3691.0                    2838.0       56404.0          356600.0   \n",
       "4            2979.0                    1526.0       30728.0          298600.0   \n",
       "\n",
       "  educational_attainment white_alone  black_alone  native_alone  asian_alone  \\\n",
       "0                  308.0       122.0       2278.0           0.0          0.0   \n",
       "1                  727.0       311.0       4292.0           0.0          0.0   \n",
       "2                  344.0        20.0       2280.0           0.0          0.0   \n",
       "3                 1008.0       211.0       2688.0          68.0         71.0   \n",
       "4                  252.0        52.0       2375.0           NaN          0.0   \n",
       "\n",
       "  native_hawaiian_pacific_islander  some_other_race_alone two_or_more  \\\n",
       "0                              0.0                    0.0        17.0   \n",
       "1                             13.0                    0.0        41.0   \n",
       "2                              0.0                    0.0       130.0   \n",
       "3                              0.0                    0.0        66.0   \n",
       "4                             15.0                    0.0        46.0   \n",
       "\n",
       "   hispanic_or_latino        city                       metro_area  \n",
       "0                37.0  Washington  Washington-Arlington-Alexandria  \n",
       "1               198.0  Washington  Washington-Arlington-Alexandria  \n",
       "2                94.0  Washington  Washington-Arlington-Alexandria  \n",
       "3               587.0  Washington  Washington-Arlington-Alexandria  \n",
       "4               491.0  Washington  Washington-Arlington-Alexandria  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se importa la libreria pandas y el archivo csv que contiene la base de datos\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"c:/Users/velj0/Downloads/census_sucio.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0407d667",
   "metadata": {},
   "source": [
    "### Se proce a identificar la datos iniciales de la base de datos.\n",
    "\n",
    "Identificamos todas las columnas del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d71377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geoid', 'name', 'total_population', 'total_population_25_over',\n",
       "       'median_income', 'median_home_value', 'educational_attainment',\n",
       "       'white_alone', 'black_alone', 'native_alone', 'asian_alone',\n",
       "       'native_hawaiian_pacific_islander', 'some_other_race_alone',\n",
       "       'two_or_more', 'hispanic_or_latino', 'city', 'metro_area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cea44",
   "metadata": {},
   "source": [
    "#### Identificar las caracteristicas de los datos.\n",
    "\n",
    "se identifican el tipo de datos, los valores nulos por fila y las columnas duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f1aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Data columns (total 17 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   geoid                             10272 non-null  float64\n",
      " 1   name                              10272 non-null  object \n",
      " 2   total_population                  10272 non-null  float64\n",
      " 3   total_population_25_over          10272 non-null  float64\n",
      " 4   median_income                     10272 non-null  object \n",
      " 5   median_home_value                 10272 non-null  object \n",
      " 6   educational_attainment            10272 non-null  object \n",
      " 7   white_alone                       10272 non-null  object \n",
      " 8   black_alone                       10272 non-null  float64\n",
      " 9   native_alone                      10272 non-null  float64\n",
      " 10  asian_alone                       10272 non-null  float64\n",
      " 11  native_hawaiian_pacific_islander  10272 non-null  object \n",
      " 12  some_other_race_alone             10272 non-null  float64\n",
      " 13  two_or_more                       10272 non-null  object \n",
      " 14  hispanic_or_latino                10272 non-null  float64\n",
      " 15  city                              10272 non-null  object \n",
      " 16  metro_area                        10272 non-null  object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 1.4+ MB\n",
      "\n",
      "---Datos nulos: \n",
      "geoid                               317\n",
      "name                                317\n",
      "total_population                    317\n",
      "total_population_25_over            317\n",
      "median_income                       317\n",
      "median_home_value                   317\n",
      "educational_attainment              317\n",
      "white_alone                         317\n",
      "black_alone                         317\n",
      "native_alone                        317\n",
      "asian_alone                         317\n",
      "native_hawaiian_pacific_islander    317\n",
      "some_other_race_alone               317\n",
      "two_or_more                         317\n",
      "hispanic_or_latino                  317\n",
      "city                                317\n",
      "metro_area                          317\n",
      "dtype: int64\n",
      "\n",
      "---Datos duplicados: 663\n"
     ]
    }
   ],
   "source": [
    "# Primer chequeo\n",
    "df.info() #Caracteristicas de los datos del dtataframe\n",
    "print(f\"\\n---Datos nulos: \\n{df.isnull().sum()}\") #Identificar total de datos nulos\n",
    "print(f\"\\n---Datos duplicados: {df.duplicated().sum()}\") #Identificar el total de columnas duplicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcdc94f",
   "metadata": {},
   "source": [
    "### Copia de seguridad.\n",
    "Crear un segundo dataframe para evitar dañar el dataframe original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6c76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038be2fa",
   "metadata": {},
   "source": [
    "## Proceso de limpieza por columna.\n",
    "\n",
    "Se procede a identificar las caracteristicas de cada columna, sus valores nulos, valores unicos y número de duplicados.\n",
    "\n",
    "Empezamos con la columna \"geoid\" la cual contiene el identificador del tracto censal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05053028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: geoid\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [1.10010075e+10            nan 1.10010077e+10 ... 6.07501570e+09\n",
      " 3.40130049e+10 2.40338015e+10]\n",
      "\n",
      "---Duplicados: 2481\n"
     ]
    }
   ],
   "source": [
    "#Identificación de los datos\n",
    "df2[\"geoid\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"geoid\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"geoid\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"geoid\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b541a",
   "metadata": {},
   "source": [
    "### Procesos.\n",
    "\n",
    "Una vez identificadas las caracteristicas de los datos que contiene esta columna se procede a ejecutar los procesos necesarios, llenar los NaN con la media de los datos en la columna y tranformar los datos de número decimal (float) a numero entero (int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47eb083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"geoid\"] = df2[\"geoid\"].fillna(df[\"geoid\"].mean()) # Relleno de NaN\n",
    "df2 [\"geoid\"]=df2 [\"geoid\"].astype(int) # Transformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d7365",
   "metadata": {},
   "source": [
    "### Comprobación.\n",
    "\n",
    "Una vez hecho lo anterior, se ejecuta una comprobación para verificar que se han ejecutado los procesos correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4189dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: geoid\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [11001007503 27727369410 11001007709 ...  6075015700 34013004900\n",
      " 24033801500]\n",
      "\n",
      "---Duplicados: 2481\n"
     ]
    }
   ],
   "source": [
    "# Comprobación del proceso\n",
    "df2[\"geoid\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"geoid\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"geoid\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"geoid\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c9cf2",
   "metadata": {},
   "source": [
    "### Limpieza.\n",
    "\n",
    "Este proceso se realizara de manera iterativa para las siguientes 16 columnas hasta terminar con todas y cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ec63a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: name\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['Census Tract 75.03, District of Columbia, District of Columbia'\n",
      " 'Census Tract 76.01, District of Columbia, District of Columbia'\n",
      " 'Census Tract 77.09, District of Columbia, District of Columbia' ...\n",
      " 'Census Tract 119, Hunterdon County, New Jersey'\n",
      " 'Census Tract 432, Morris County, New Jersey'\n",
      " 'Census Tract 1304.06, Forsyth County, Georgia']\n",
      "\n",
      "---Duplicados: 2501\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"name\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"name\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"name\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"name\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4f0fc",
   "metadata": {},
   "source": [
    "### Columnas string.\n",
    "\n",
    "Para las columnas string en lugar de sustituir los NaN por la media, se sustituyen por el dato que se encuentren en la fila inferior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9833e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"name\"] = df2[\"name\"].bfill()  # rellenar NaN con los datos de la fila inferior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e911abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: name\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10589 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: ['Census Tract 75.03, District of Columbia, District of Columbia'\n",
      " 'Census Tract 76.01, District of Columbia, District of Columbia'\n",
      " 'Census Tract 77.09, District of Columbia, District of Columbia' ...\n",
      " 'Census Tract 119, Hunterdon County, New Jersey'\n",
      " 'Census Tract 432, Morris County, New Jersey'\n",
      " 'Census Tract 1304.06, Forsyth County, Georgia']\n",
      "\n",
      "---Duplicados: 2502\n"
     ]
    }
   ],
   "source": [
    "# IComprobación de la limpieza\n",
    "df2[\"name\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"name\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"name\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"name\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1facd12",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: total_population\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [2454. 4855. 2524. ... 5330. 4828. 1348.]\n",
      "\n",
      "---Duplicados: 5755\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"total_population\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"total_population\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"total_population\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"total_population\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "410f6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"total_population\"] = df2[\"total_population\"].fillna(df[\"total_population\"].mean()) #Rellenar NaN con la media\n",
    "df2 [\"total_population\"]=df2 [\"total_population\"].astype(int) #Convertir a entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ad0b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: total_population\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [2454 4855 2524 ... 5330 4828 1348]\n",
      "\n",
      "---Duplicados: 5756\n"
     ]
    }
   ],
   "source": [
    "# Comprobación de la limpieza\n",
    "df2[\"total_population\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"total_population\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"total_population\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"total_population\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1259bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: total_population_25_over\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [1425. 3463. 1817. ... 1618. 4907. 2324.]\n",
      "\n",
      "---Duplicados: 6542\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"total_population_25_over\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"total_population_25_over\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"total_population_25_over\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"total_population_25_over\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e0ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"total_population_25_over\"] = df2[\"total_population_25_over\"].fillna(df[\"total_population_25_over\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"total_population_25_over\"]=df2 [\"total_population_25_over\"].astype(int) # onvertir a entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "497fde26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: total_population_25_over\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [1425 3463 1817 ... 1618 4907 2324]\n",
      "\n",
      "---Duplicados: 6542\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"total_population_25_over\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"total_population_25_over\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"total_population_25_over\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"total_population_25_over\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb1dc55",
   "metadata": {},
   "source": [
    "## Columnas string a númericas.\n",
    "\n",
    "Para estas columnas es necesario identificar y eliminar cualquier caracter que no se numerico pues estos no son relevantes y nos complican la transformacion de los datos,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "506d379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: median_income\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['26250.0' '34840.0' '33750.0' ... '105461.0' '103730.0' '113856.0']\n",
      "\n",
      "---Duplicados: 3538\n",
      "\n",
      "---Caracteres extraños: 0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "         ... \n",
      "10584    True\n",
      "10585    True\n",
      "10586    True\n",
      "10587    True\n",
      "10588    True\n",
      "Name: median_income, Length: 10589, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"median_income\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"median_income\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"median_income\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"median_income\"]).sum()}\") #Contar duplicados\n",
    "print(f\"\\n---Caracteres extraños: {df2[\"median_income\"].str.contains(r'\\D', regex=True)}\") #Detectar caracteres extraños"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23920694",
   "metadata": {},
   "source": [
    "### Datos no númericos.\n",
    "Para esta columna, \"median_income\", la identificacion de los datos no númericos se reliza con el comando: f\"\\n---Caracteres extraños: \"{df2[\"median_income\"].str.contains(r'\\D', regex=True)}\" y la sustitución de estos sera con el comando: \"df2[\"median_income\"] = df2[\"median_income\"].str.replace(r'\\D', '0', regex=True)\" en los cuales el caracter \\D nos es util para identificar todos los caracteres no númericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7be5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"median_income\"] = df2[\"median_income\"].str.replace(r'\\D', '0', regex=True) # Sustituir caracteres extraños\n",
    "df2 [\"median_income\"]=df2 [\"median_income\"].astype(float) # Trabsformar a númerico decimal\n",
    "df2[\"median_income\"] = df2[\"median_income\"].fillna(df2[\"median_income\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"median_income\"]=df2 [\"median_income\"].astype(int) # Transformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abedd15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: median_income\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [ 2625000  3484000  3375000 ... 10546100 10373000 11385600]\n",
      "\n",
      "---Duplicados: 3538\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"median_income\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"median_income\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"median_income\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"median_income\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4696498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: median_home_value\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [nan '255000.0' '250000.0' ... '1543100.0' '1505700.0' '272000.0']\n",
      "\n",
      "---Duplicados: 5687\n",
      "\n",
      "---Caracteres extraños: 0         NaN\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "         ... \n",
      "10584    True\n",
      "10585    True\n",
      "10586    True\n",
      "10587    True\n",
      "10588    True\n",
      "Name: median_home_value, Length: 10589, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"median_home_value\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"median_home_value\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"median_home_value\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"median_home_value\"]).sum()}\") #Contar duplicados\n",
    "print(f\"\\n---Caracteres extraños: {df2[\"median_home_value\"].str.contains(r'\\D', regex=True)}\") #Detectar caracteres extraños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b5211c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"median_home_value\"] = df2[\"median_home_value\"].str.replace(r'\\D', '0', regex=True) # Sustituir caracteres extraños\n",
    "df2 [\"median_home_value\"]=df2 [\"median_home_value\"].astype(float) # Trabsformar a númerico decimal\n",
    "df2[\"median_home_value\"] = df2[\"median_home_value\"].fillna(df2[\"median_home_value\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"median_home_value\"]=df2 [\"median_home_value\"].astype(int) # Transformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef6bacbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: median_home_value\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [2834459653   25500000   25000000 ...  154310000  150570000   27200000]\n",
      "\n",
      "---Duplicados: 5687\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"median_home_value\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"median_home_value\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"median_home_value\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"median_home_value\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aac05356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: educational_attainment\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['308.0' '727.0' '344.0' ... '5753.0' '1098.0' '3175.0']\n",
      "\n",
      "---Duplicados: 7687\n",
      "\n",
      "---Caracteres extraños: 0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "         ... \n",
      "10584    True\n",
      "10585    True\n",
      "10586    True\n",
      "10587    True\n",
      "10588    True\n",
      "Name: educational_attainment, Length: 10589, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"educational_attainment\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"educational_attainment\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"educational_attainment\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"educational_attainment\"]).sum()}\") #Contar duplicados\n",
    "print(f\"\\n---Caracteres extraños: {df2[\"educational_attainment\"].str.contains(r'\\D', regex=True)}\") #Detectar caracteres extraños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11311c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"educational_attainment\"] = df2[\"educational_attainment\"].str.replace(r'\\D', '0', regex=True) # Sustituir caracteres extraños\n",
    "df2 [\"educational_attainment\"]=df2 [\"educational_attainment\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"educational_attainment\"] = df2[\"educational_attainment\"].fillna(df2[\"educational_attainment\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"educational_attainment\"]=df2 [\"educational_attainment\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad93d984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: educational_attainment\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [ 30800  72700  34400 ... 575300 109800 317500]\n",
      "\n",
      "---Duplicados: 7688\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"educational_attainment\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"educational_attainment\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"educational_attainment\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"educational_attainment\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc4d77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: white_alone\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['122.0' '311.0' '20.0' ... '1367.0' '200.0' '259.0']\n",
      "\n",
      "---Duplicados: 6581\n",
      "\n",
      "---Caracteres extraños: 0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "         ... \n",
      "10584    True\n",
      "10585     NaN\n",
      "10586    True\n",
      "10587    True\n",
      "10588    True\n",
      "Name: white_alone, Length: 10589, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"white_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"white_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"white_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"white_alone\"]).sum()}\") #Contar duplicados\n",
    "print(f\"\\n---Caracteres extraños: {df2[\"white_alone\"].str.contains(r'\\D', regex=True)}\") #Detectar caracteres extraños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80ed2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"white_alone\"] = df2[\"white_alone\"].str.replace(r'\\D', '0', regex=True) # Sustituir caracteres extraños\n",
    "df2 [\"white_alone\"]=df2 [\"white_alone\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"white_alone\"] = df2[\"white_alone\"].fillna(df2[\"white_alone\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"white_alone\"]=df2 [\"white_alone\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f64ecffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: white_alone\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [ 12200  31100   2000 ... 136700  20000  25900]\n",
      "\n",
      "---Duplicados: 6582\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"white_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"white_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"white_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"white_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27c1bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: black_alone\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [2278. 4292. 2280. ... 2168.  864.  703.]\n",
      "\n",
      "---Duplicados: 7987\n"
     ]
    }
   ],
   "source": [
    "# Identificación de datos\n",
    "df2[\"black_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"black_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"black_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"black_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7efb827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2 [\"black_alone\"]=df2 [\"black_alone\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"black_alone\"] = df2[\"black_alone\"].fillna(df2[\"black_alone\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"black_alone\"]=df2 [\"black_alone\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c99c6908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: black_alone\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [2278 4292 2280 ... 2168  864  703]\n",
      "\n",
      "---Duplicados: 7988\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"black_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"black_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"black_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"black_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d1d8a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: native_alone\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [  0.  68.  nan  27.   7.   9.  28.  16.   4.  13.   6.  20.  17.  83.\n",
      "   5.  10.  53.  77.  32.  14.  19.  40.  15.  30.  64.  11.   1.  23.\n",
      "  31.  60.   3.  24. 304.  82.  26.  39.  29.  34.  52.  37.  22.   8.\n",
      " 144.  18.  21.  49.  61.  45.  43.  44. 104.  67.   2.  25.  73.  59.\n",
      " 101.  36.  48.  54.  63. 115.  46.  89. 197.  41.  33.  78.  62.  57.\n",
      "  81.  38.  70. 158.  56.  12. 177. 100. 228. 126.  58.  66. 114.  42.\n",
      "  50.  65.  51. 108.  80.  94.  35.  79.  87. 276. 130. 162. 221. 107.\n",
      " 156.  47. 146.  99.  96. 134. 111.  76.  85.  71.  75. 233. 195.  84.\n",
      "  93. 123. 153. 433. 282.  74. 189.  69. 127. 330. 529. 128. 139. 193.\n",
      " 176. 207. 252. 106. 764. 213.  86. 256. 345. 125. 480. 227. 105. 159.\n",
      "  98. 165. 124. 102.  97.  95. 109. 110. 208.  88.  72. 122. 342. 168.\n",
      "  55. 167. 185. 112.  91. 271.  90. 129. 155. 142. 224. 118. 239. 152.\n",
      " 150. 399. 119. 192. 131. 103. 151. 204. 148. 226. 179. 120. 218. 170.\n",
      " 262. 231. 137. 121. 287. 196. 178. 209. 261. 329. 147. 116. 477.  92.\n",
      " 229. 280. 187. 164. 154. 182. 265. 200. 135. 175. 315. 216. 140. 601.\n",
      " 502. 180. 234. 113. 260. 160. 263. 211. 141. 132. 285. 428. 205. 258.]\n",
      "\n",
      "---Duplicados: 10365\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"native_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"native_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"native_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"native_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c438703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2 [\"native_alone\"]=df2 [\"native_alone\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"native_alone\"] = df2[\"native_alone\"].fillna(df2[\"black_alone\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"native_alone\"]=df2 [\"native_alone\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67832f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: native_alone\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [  0  68 910  27   7   9  28  16   4  13   6  20  17  83   5  10  53  77\n",
      "  32  14  19  40  15  30  64  11   1  23  31  60   3  24 304  82  26  39\n",
      "  29  34  52  37  22   8 144  18  21  49  61  45  43  44 104  67   2  25\n",
      "  73  59 101  36  48  54  63 115  46  89 197  41  33  78  62  57  81  38\n",
      "  70 158  56  12 177 100 228 126  58  66 114  42  50  65  51 108  80  94\n",
      "  35  79  87 276 130 162 221 107 156  47 146  99  96 134 111  76  85  71\n",
      "  75 233 195  84  93 123 153 433 282  74 189  69 127 330 529 128 139 193\n",
      " 176 207 252 106 764 213  86 256 345 125 480 227 105 159  98 165 124 102\n",
      "  97  95 109 110 208  88  72 122 342 168  55 167 185 112  91 271  90 129\n",
      " 155 142 224 118 239 152 150 399 119 192 131 103 151 204 148 226 179 120\n",
      " 218 170 262 231 137 121 287 196 178 209 261 329 147 116 477  92 229 280\n",
      " 187 164 154 182 265 200 135 175 315 216 140 601 502 180 234 113 260 160\n",
      " 263 211 141 132 285 428 205 258]\n",
      "\n",
      "---Duplicados: 10365\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"native_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"native_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"native_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"native_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1119ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: asian_alone\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [   0.   71.   90. ... 3814. 1962. 3428.]\n",
      "\n",
      "---Duplicados: 8743\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"asian_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"asian_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"asian_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"asian_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "882faaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2 [\"asian_alone\"]=df2 [\"asian_alone\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"asian_alone\"] = df2[\"asian_alone\"].fillna(df2[\"asian_alone\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"asian_alone\"]=df2 [\"asian_alone\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "793a4ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: asian_alone\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [   0   71   90 ... 3814 1962 3428]\n",
      "\n",
      "---Duplicados: 8744\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"asian_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"asian_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"asian_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"asian_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ac17e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: native_hawaiian_pacific_islander\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['0.0' '13.0' '15.0' '42.0' '16.0' nan 'Auto%#' '18.0' '7.0' '27.0' '14.0'\n",
      " '8.0' '34.0' '131.0' '6.0' '21.0' '5.0' '12.0' '89.0' '9.0' '10.0' '33.0'\n",
      " '4.0' '1.0' '3.0' '97.0' '11.0' '132.0' '19.0' '25.0' '41.0' '17.0'\n",
      " '26.0' '24.0' '23.0' '30.0' '38.0' '22.0' '32.0' '44.0' '29.0' '130.0'\n",
      " '48.0' '39.0' '74.0' '36.0' '68.0' '53.0' '2.0' '50.0' '20.0' '62.0'\n",
      " '51.0' '180.0' '28.0' '56.0' '66.0' '124.0' '52.0' '220.0' '45.0' '160.0'\n",
      " '227.0' '82.0' '70.0' '83.0' '46.0' '142.0' '31.0' '134.0' '104.0' '86.0'\n",
      " '313.0' '84.0' '113.0' '35.0' '128.0' '95.0' '156.0' '125.0' '292.0'\n",
      " '85.0' '43.0' '183.0' '78.0' '49.0' '79.0' '55.0' '129.0' '40.0' '204.0'\n",
      " '222.0' '105.0' '126.0' '219.0' '159.0' '57.0' '157.0' '273.0' '298.0'\n",
      " '122.0' '115.0' '47.0' '77.0' '153.0' '141.0' '137.0' '107.0' '76.0'\n",
      " '164.0' '60.0' '99.0' '92.0' '155.0' '133.0' '72.0' '179.0' '244.0'\n",
      " '274.0' '65.0' '254.0' '135.0' '190.0' '251.0' '120.0' '71.0' '140.0'\n",
      " '281.0' '100.0' '235.0' '464.0' '144.0' '37.0' '186.0' '143.0' '119.0'\n",
      " '118.0' '201.0' '324.0' '61.0' '75.0' '54.0' '111.0' '266.0' '465.0'\n",
      " '371.0' '460.0' '213.0' '293.0' '203.0' '136.0' '669.0' '892.0' '500.0'\n",
      " '286.0' '668.0' '58.0' '812.0' '195.0' '533.0' '342.0' '191.0' '88.0'\n",
      " '127.0' '117.0' '171.0' '173.0' '80.0' '91.0' '96.0' '108.0' '73.0'\n",
      " '231.0']\n",
      "\n",
      "---Duplicados: 10416\n",
      "\n",
      "---Caracteres extraños: 0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "         ... \n",
      "10584    True\n",
      "10585    True\n",
      "10586    True\n",
      "10587    True\n",
      "10588    True\n",
      "Name: native_hawaiian_pacific_islander, Length: 10589, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"native_hawaiian_pacific_islander\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"native_hawaiian_pacific_islander\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"native_hawaiian_pacific_islander\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"native_hawaiian_pacific_islander\"]).sum()}\") #Contar duplicados\n",
    "print(f\"\\n---Caracteres extraños: {df2[\"native_hawaiian_pacific_islander\"].str.contains(r'\\D', regex=True)}\") #Detectar caracteres extraños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8583458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"native_hawaiian_pacific_islander\"] = df2[\"native_hawaiian_pacific_islander\"].str.replace(r'\\D', '0', regex=True) # Sustituir caracteres extraños\n",
    "df2 [\"native_hawaiian_pacific_islander\"]=df2 [\"native_hawaiian_pacific_islander\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"native_hawaiian_pacific_islander\"] = df2[\"native_hawaiian_pacific_islander\"].fillna(df2[\"native_hawaiian_pacific_islander\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"native_hawaiian_pacific_islander\"]=df2 [\"native_hawaiian_pacific_islander\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c6c3056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: native_hawaiian_pacific_islander\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [    0  1300  1500  4200  1600   508  1800   700  2700  1400   800  3400\n",
      " 13100   600  2100   500  1200  8900   900  1000  3300   400   100   300\n",
      "  9700  1100 13200  1900  2500  4100  1700  2600  2400  2300  3000  3800\n",
      "  2200  3200  4400  2900 13000  4800  3900  7400  3600  6800  5300   200\n",
      "  5000  2000  6200  5100 18000  2800  5600  6600 12400  5200 22000  4500\n",
      " 16000 22700  8200  7000  8300  4600 14200  3100 13400 10400  8600 31300\n",
      "  8400 11300  3500 12800  9500 15600 12500 29200  8500  4300 18300  7800\n",
      "  4900  7900  5500 12900  4000 20400 22200 10500 12600 21900 15900  5700\n",
      " 15700 27300 29800 12200 11500  4700  7700 15300 14100 13700 10700  7600\n",
      " 16400  6000  9900  9200 15500 13300  7200 17900 24400 27400  6500 25400\n",
      " 13500 19000 25100 12000  7100 14000 28100 10000 23500 46400 14400  3700\n",
      " 18600 14300 11900 11800 20100 32400  6100  7500  5400 11100 26600 46500\n",
      " 37100 46000 21300 29300 20300 13600 66900 89200 50000 28600 66800  5800\n",
      " 81200 19500 53300 34200 19100  8800 12700 11700 17100 17300  8000  9100\n",
      "  9600 10800  7300 23100]\n",
      "\n",
      "---Duplicados: 10417\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"native_hawaiian_pacific_islander\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"native_hawaiian_pacific_islander\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"native_hawaiian_pacific_islander\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"native_hawaiian_pacific_islander\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efadc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: some_other_race_alone\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [0.000e+00 7.000e+00       nan 1.100e+01 9.000e+00 8.000e+00 4.600e+01\n",
      " 1.500e+01 1.660e+02 1.000e+01 2.200e+01 3.200e+01 3.100e+01 8.700e+01\n",
      " 1.200e+01 2.000e+01 1.800e+01 1.700e+01 1.010e+02 2.100e+01 4.000e+00\n",
      " 1.400e+01 1.730e+02 2.600e+01 2.400e+01 2.300e+01 3.500e+01 1.300e+01\n",
      " 8.800e+01 1.900e+01 6.000e+00 6.700e+01 3.000e+01 3.400e+01 9.300e+01\n",
      " 1.600e+01 1.460e+02 3.000e+00 5.000e+00 5.200e+01 6.400e+01 4.400e+01\n",
      " 4.300e+01 4.100e+01 1.420e+02 2.000e+00 2.960e+02 2.700e+01 7.200e+01\n",
      " 3.800e+01 5.100e+01 4.500e+01 3.300e+01 4.700e+01 3.700e+01 2.500e+01\n",
      " 3.820e+02 6.500e+01 7.700e+01 2.900e+01 5.600e+01 3.600e+01 8.200e+01\n",
      " 5.500e+01 1.350e+02 6.600e+01 1.090e+02 6.200e+01 5.400e+01 2.220e+02\n",
      " 2.000e+02 7.000e+01 5.900e+01 6.900e+01 1.140e+02 2.920e+02 3.900e+01\n",
      " 4.200e+01 5.700e+01 2.780e+02 2.600e+02 4.000e+01 5.800e+01 9.800e+01\n",
      " 8.400e+01 2.050e+02 7.300e+01 1.000e+02 5.000e+01 1.290e+02 1.820e+02\n",
      " 4.900e+01 1.250e+02 8.000e+01 6.100e+01 8.500e+01 1.640e+02 1.430e+02\n",
      " 2.800e+01 1.110e+02 1.360e+02 1.630e+02 6.800e+01 1.120e+02 1.490e+02\n",
      " 6.000e+01 1.580e+02 1.030e+02 1.700e+02 1.570e+02 1.040e+02 4.800e+01\n",
      " 1.300e+02 7.900e+01 1.000e+00 6.300e+01 1.080e+02 9.200e+01 1.620e+02\n",
      " 1.410e+02 8.300e+01 1.170e+02 1.590e+02 9.600e+01 1.190e+02 1.020e+02\n",
      " 1.280e+02 9.100e+01 1.240e+02 2.310e+02 4.140e+02 8.100e+01 8.900e+01\n",
      " 2.520e+02 1.060e+02 1.310e+02 8.600e+01 1.390e+02 9.400e+01 1.860e+02\n",
      " 5.300e+01 1.400e+02 9.500e+01 2.430e+02 2.130e+02 1.480e+02 2.860e+02\n",
      " 1.220e+02 7.100e+01 1.100e+02 2.740e+02 2.570e+02 1.260e+02 1.650e+02\n",
      " 7.400e+01 2.070e+02 3.080e+02 2.450e+02 2.490e+02 2.840e+02 1.770e+02\n",
      " 5.620e+02 1.750e+02 5.710e+02 3.830e+02 1.130e+02 2.890e+02 1.830e+02\n",
      " 2.720e+02 1.540e+02 1.150e+02 1.050e+02 1.690e+02 1.950e+02 1.330e+02\n",
      " 3.040e+02 1.670e+02 1.740e+02 1.340e+02 1.940e+02 1.450e+02 1.530e+02\n",
      " 1.610e+02 2.770e+02 1.180e+02 9.700e+01 3.380e+02 7.600e+01 2.910e+02\n",
      " 1.270e+02 1.370e+02 2.630e+02 2.060e+02 6.370e+02 1.890e+02 1.780e+02\n",
      " 3.570e+02 2.510e+02 1.230e+02 1.320e+02 1.070e+02 3.340e+02 7.800e+01\n",
      " 1.520e+02 1.720e+02 2.830e+02 9.000e+01 2.200e+02 2.460e+02 2.290e+02\n",
      " 4.680e+02 2.550e+02 1.470e+02 6.270e+02 1.980e+02 2.300e+02 5.830e+02\n",
      " 3.540e+02 5.260e+02 2.790e+02 5.700e+02 3.650e+02 1.900e+02 4.490e+02\n",
      " 7.500e+01 4.210e+02 1.160e+02 3.390e+02 1.960e+02 6.570e+02 2.330e+02\n",
      " 2.160e+02 2.500e+02 9.900e+01 2.030e+02 1.510e+02 1.840e+02 4.400e+02\n",
      " 3.550e+02 4.010e+02 2.250e+02 2.940e+02 1.870e+02 1.790e+02 2.560e+02\n",
      " 1.910e+02 3.250e+02 2.270e+02 2.710e+02 1.440e+02 2.800e+02 1.710e+02\n",
      " 4.440e+02 3.060e+02 5.270e+02 2.480e+02 1.210e+02 5.240e+02 2.120e+02\n",
      " 2.100e+02 8.240e+02 5.970e+02 3.720e+02 2.730e+02 5.190e+02 4.890e+02\n",
      " 3.260e+02 5.590e+02 5.690e+02 7.140e+02 3.750e+02 5.390e+02 3.440e+02\n",
      " 4.270e+02 1.200e+02 1.325e+03 3.120e+02 5.420e+02 3.620e+02 4.650e+02\n",
      " 6.150e+02 4.030e+02 2.140e+02 3.800e+02 3.000e+02 7.980e+02 8.550e+02\n",
      " 4.850e+02 3.280e+02 4.760e+02 7.810e+02 4.990e+02 6.020e+02 8.160e+02\n",
      " 3.400e+02 1.760e+02 9.420e+02 9.840e+02 9.720e+02 6.530e+02 3.790e+02\n",
      " 3.810e+02 9.400e+02 1.251e+03 1.550e+02 4.190e+02 2.010e+02 3.030e+02\n",
      " 3.430e+02 3.410e+02]\n",
      "\n",
      "---Duplicados: 10279\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"some_other_race_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"some_other_race_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"some_other_race_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"some_other_race_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ee4efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2 [\"some_other_race_alone\"]=df2 [\"some_other_race_alone\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"some_other_race_alone\"] = df2[\"some_other_race_alone\"].fillna(df2[\"some_other_race_alone\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"some_other_race_alone\"]=df2 [\"some_other_race_alone\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "949f0f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: some_other_race_alone\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [   0    7   22   11    9    8   46   15  166   10   32   31   87   12\n",
      "   20   18   17  101   21    4   14  173   26   24   23   35   13   88\n",
      "   19    6   67   30   34   93   16  146    3    5   52   64   44   43\n",
      "   41  142    2  296   27   72   38   51   45   33   47   37   25  382\n",
      "   65   77   29   56   36   82   55  135   66  109   62   54  222  200\n",
      "   70   59   69  114  292   39   42   57  278  260   40   58   98   84\n",
      "  205   73  100   50  129  182   49  125   80   61   85  164  143   28\n",
      "  111  136  163   68  112  149   60  158  103  170  157  104   48  130\n",
      "   79    1   63  108   92  162  141   83  117  159   96  119  102  128\n",
      "   91  124  231  414   81   89  252  106  131   86  139   94  186   53\n",
      "  140   95  243  213  148  286  122   71  110  274  257  126  165   74\n",
      "  207  308  245  249  284  177  562  175  571  383  113  289  183  272\n",
      "  154  115  105  169  195  133  304  167  174  134  194  145  153  161\n",
      "  277  118   97  338   76  291  127  137  263  206  637  189  178  357\n",
      "  251  123  132  107  334   78  152  172  283   90  220  246  229  468\n",
      "  255  147  627  198  230  583  354  526  279  570  365  190  449   75\n",
      "  421  116  339  196  657  233  216  250   99  203  151  184  440  355\n",
      "  401  225  294  187  179  256  191  325  227  271  144  280  171  444\n",
      "  306  527  248  121  524  212  210  824  597  372  273  519  489  326\n",
      "  559  569  714  375  539  344  427  120 1325  312  542  362  465  615\n",
      "  403  214  380  300  798  855  485  328  476  781  499  602  816  340\n",
      "  176  942  984  972  653  379  381  940 1251  155  419  201  303  343\n",
      "  341]\n",
      "\n",
      "---Duplicados: 10280\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"some_other_race_alone\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"some_other_race_alone\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"some_other_race_alone\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"some_other_race_alone\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "512d7fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: two_or_more\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['17.0' '41.0' '130.0' '66.0' '46.0' nan '59.0' '21.0' '103.0' '244.0'\n",
      " '102.0' '447.0' '79.0' '159.0' '215.0' '72.0' '122.0' '82.0' '83.0'\n",
      " '89.0' 'Auto%#' '228.0' '94.0' '129.0' '74.0' '40.0' '179.0' '241.0'\n",
      " '0.0' '127.0' '47.0' '48.0' '107.0' '86.0' '171.0' '16.0' '38.0' '85.0'\n",
      " '87.0' '10.0' '33.0' '181.0' '6.0' '11.0' '88.0' '42.0' '147.0' '201.0'\n",
      " '99.0' '165.0' '226.0' '84.0' '206.0' '145.0' '29.0' '70.0' '19.0' '14.0'\n",
      " '95.0' '100.0' '51.0' '98.0' '23.0' '68.0' '52.0' '63.0' '5.0' '78.0'\n",
      " '67.0' '26.0' '12.0' '109.0' '8.0' '164.0' '132.0' '153.0' '64.0' '191.0'\n",
      " '22.0' '50.0' '60.0' '117.0' '58.0' '32.0' '44.0' '24.0' '69.0' '43.0'\n",
      " '253.0' '53.0' '110.0' '137.0' '212.0' '120.0' '49.0' '112.0' '104.0'\n",
      " '61.0' '134.0' '77.0' '123.0' '121.0' '9.0' '39.0' '34.0' '124.0' '268.0'\n",
      " '118.0' '126.0' '149.0' '235.0' '328.0' '152.0' '20.0' '97.0' '292.0'\n",
      " '170.0' '583.0' '139.0' '392.0' '184.0' '55.0' '541.0' '141.0' '411.0'\n",
      " '144.0' '263.0' '236.0' '196.0' '173.0' '204.0' '288.0' '176.0' '415.0'\n",
      " '587.0' '407.0' '239.0' '586.0' '331.0' '282.0' '280.0' '187.0' '163.0'\n",
      " '229.0' '316.0' '387.0' '62.0' '27.0' '285.0' '135.0' '90.0' '151.0'\n",
      " '211.0' '319.0' '294.0' '217.0' '157.0' '190.0' '265.0' '57.0' '231.0'\n",
      " '301.0' '71.0' '255.0' '37.0' '65.0' '15.0' '298.0' '142.0' '115.0'\n",
      " '81.0' '213.0' '210.0' '223.0' '143.0' '254.0' '54.0' '553.0' '35.0'\n",
      " '150.0' '76.0' '200.0' '315.0' '221.0' '36.0' '133.0' '189.0' '299.0'\n",
      " '227.0' '419.0' '306.0' '195.0' '323.0' '13.0' '80.0' '91.0' '309.0'\n",
      " '304.0' '138.0' '214.0' '116.0' '155.0' '259.0' '119.0' '125.0' '131.0'\n",
      " '568.0' '486.0' '222.0' '31.0' '182.0' '389.0' '327.0' '106.0' '93.0'\n",
      " '169.0' '240.0' '448.0' '405.0' '175.0' '156.0' '252.0' '355.0' '249.0'\n",
      " '73.0' '247.0' '185.0' '242.0' '219.0' '224.0' '230.0' '336.0' '136.0'\n",
      " '158.0' '318.0' '261.0' '114.0' '225.0' '45.0' '167.0' '166.0' '140.0'\n",
      " '174.0' '276.0' '172.0' '192.0' '148.0' '359.0' '199.0' '295.0' '208.0'\n",
      " '258.0' '75.0' '108.0' '324.0' '420.0' '18.0' '251.0' '25.0' '193.0'\n",
      " '186.0' '111.0' '363.0' '337.0' '92.0' '161.0' '7.0' '183.0' '177.0'\n",
      " '30.0' '197.0' '243.0' '321.0' '146.0' '218.0' '4.0' '473.0' '160.0'\n",
      " '346.0' '96.0' '264.0' '220.0' '317.0' '330.0' '310.0' '237.0' '604.0'\n",
      " '245.0' '790.0' '287.0' '957.0' '600.0' '437.0' '714.0' '209.0' '216.0'\n",
      " '273.0' '293.0' '272.0' '475.0' '364.0' '361.0' '380.0' '358.0' '485.0'\n",
      " '275.0' '267.0' '499.0' '332.0' '281.0' '417.0' '753.0' '302.0' '356.0'\n",
      " '312.0' '286.0' '180.0' '232.0' '168.0' '205.0' '426.0' '262.0' '646.0'\n",
      " '284.0' '386.0' '735.0' '383.0' '524.0' '269.0' '277.0' '291.0' '441.0'\n",
      " '406.0' '202.0' '457.0' '296.0' '425.0' '384.0' '424.0' '344.0' '289.0'\n",
      " '238.0' '1.0' '28.0' '410.0' '162.0' '198.0' '2.0' '684.0' '56.0' '178.0'\n",
      " '101.0' '260.0' '350.0' '404.0' '154.0' '256.0' '559.0' '246.0' '369.0'\n",
      " '326.0' '308.0' '453.0' '349.0' '307.0' '266.0' '445.0' '341.0' '348.0'\n",
      " '432.0' '421.0' '105.0' '257.0' '334.0' '188.0' '300.0' '402.0' '343.0'\n",
      " '207.0' '113.0' '365.0' '335.0' '526.0' '128.0' '345.0' '311.0' '333.0'\n",
      " '438.0' '347.0' '381.0' '313.0' '314.0' '354.0' '412.0' '467.0' '374.0'\n",
      " '352.0' '379.0' '283.0' '305.0' '3.0' '366.0' '668.0' '250.0' '579.0'\n",
      " '544.0' '469.0' '377.0' '548.0' '642.0' '612.0' '440.0' '329.0' '478.0'\n",
      " '270.0' '455.0' '362.0' '401.0' '520.0' '423.0' '351.0' '510.0' '513.0'\n",
      " '357.0' '274.0' '394.0' '433.0' '562.0' '353.0' '431.0' '233.0' '370.0'\n",
      " '439.0' '503.0' '194.0' '529.0' '403.0' '574.0' '655.0' '414.0' '493.0'\n",
      " '436.0' '588.0' '339.0' '597.0' '492.0' '271.0' '511.0' '633.0' '442.0'\n",
      " '496.0' '368.0' '525.0' '452.0' '360.0' '632.0' '517.0' '522.0' '234.0'\n",
      " '489.0' '778.0' '422.0' '504.0' '897.0' '1246.0' '325.0' '290.0' '874.0'\n",
      " '527.0' '390.0' '538.0' '547.0' '521.0' '413.0' '539.0' '464.0' '688.0'\n",
      " '340.0' '248.0' '278.0' '519.0' '303.0' '647.0' '279.0' '536.0' '378.0'\n",
      " '398.0' '509.0' '481.0' '203.0' '555.0' '557.0' '450.0' '371.0' '297.0'\n",
      " '427.0' '399.0' '506.0' '444.0' '497.0' '400.0' '372.0' '565.0' '451.0'\n",
      " '320.0' '1002.0' '543.0' '495.0' '396.0' '501.0' '849.0' '459.0' '472.0'\n",
      " '477.0' '808.0' '463.0' '471.0' '373.0' '395.0' '491.0']\n",
      "\n",
      "---Duplicados: 10069\n",
      "\n",
      "---Caracteres extraños: 0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "         ... \n",
      "10584    True\n",
      "10585     NaN\n",
      "10586    True\n",
      "10587    True\n",
      "10588    True\n",
      "Name: two_or_more, Length: 10589, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"two_or_more\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"two_or_more\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"two_or_more\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"two_or_more\"]).sum()}\") #Contar duplicados\n",
    "print(f\"\\n---Caracteres extraños: {df2[\"two_or_more\"].str.contains(r'\\D', regex=True)}\") #Detectar caracteres extraños"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a22c212",
   "metadata": {},
   "source": [
    "### String a númerico\n",
    "\n",
    "Como hemos visto es un proceso mas largo la identificacin y eliminacion de los elementos no necesarios, sin embargo este se llevo a cabo en las columnas: \"median_income\",   \"median_home_value\",  \"educational_attainment\" , \"native_hawaiian_pacific_islander\", \"two_or_more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03dcb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"two_or_more\"] = df2[\"two_or_more\"].str.replace(r'\\D', '0', regex=True) # Sustituir caracteres extraños\n",
    "df2 [\"two_or_more\"]=df2 [\"two_or_more\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"two_or_more\"] = df2[\"two_or_more\"].fillna(df2[\"two_or_more\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"two_or_more\"]=df2 [\"two_or_more\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "411d7aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: two_or_more\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [  1700   4100  13000   6600   4600   9891   5900   2100  10300  24400\n",
      "  10200  44700   7900  15900  21500   7200  12200   8200   8300   8900\n",
      "      0  22800   9400  12900   7400   4000  17900  24100  12700   4700\n",
      "   4800  10700   8600  17100   1600   3800   8500   8700   1000   3300\n",
      "  18100    600   1100   8800   4200  14700  20100   9900  16500  22600\n",
      "   8400  20600  14500   2900   7000   1900   1400   9500  10000   5100\n",
      "   9800   2300   6800   5200   6300    500   7800   6700   2600   1200\n",
      "  10900    800  16400  13200  15300   6400  19100   2200   5000   6000\n",
      "  11700   5800   3200   4400   2400   6900   4300  25300   5300  11000\n",
      "  13700  21200  12000   4900  11200  10400   6100  13400   7700  12300\n",
      "  12100    900   3900   3400  12400  26800  11800  12600  14900  23500\n",
      "  32800  15200   2000   9700  29200  17000  58300  13900  39200  18400\n",
      "   5500  54100  14100  41100  14400  26300  23600  19600  17300  20400\n",
      "  28800  17600  41500  58700  40700  23900  58600  33100  28200  28000\n",
      "  18700  16300  22900  31600  38700   6200   2700  28500  13500   9000\n",
      "  15100  21100  31900  29400  21700  15700  19000  26500   5700  23100\n",
      "  30100   7100  25500   3700   6500   1500  29800  14200  11500   8100\n",
      "  21300  21000  22300  14300  25400   5400  55300   3500  15000   7600\n",
      "  20000  31500  22100   3600  13300  18900  29900  22700  41900  30600\n",
      "  19500  32300   1300   8000   9100  30900  30400  13800  21400  11600\n",
      "  15500  25900  11900  12500  13100  56800  48600  22200   3100  18200\n",
      "  38900  32700  10600   9300  16900  24000  44800  40500  17500  15600\n",
      "  25200  35500  24900   7300  24700  18500  24200  21900  22400  23000\n",
      "  33600  13600  15800  31800  26100  11400  22500   4500  16700  16600\n",
      "  14000  17400  27600  17200  19200  14800  35900  19900  29500  20800\n",
      "  25800   7500  10800  32400  42000   1800  25100   2500  19300  18600\n",
      "  11100  36300  33700   9200  16100    700  18300  17700   3000  19700\n",
      "  24300  32100  14600  21800    400  47300  16000  34600   9600  26400\n",
      "  22000  31700  33000  31000  23700  60400  24500  79000  28700  95700\n",
      "  60000  43700  71400  20900  21600  27300  29300  27200  47500  36400\n",
      "  36100  38000  35800  48500  27500  26700  49900  33200  28100  41700\n",
      "  75300  30200  35600  31200  28600  18000  23200  16800  20500  42600\n",
      "  26200  64600  28400  38600  73500  38300  52400  26900  27700  29100\n",
      "  44100  40600  20200  45700  29600  42500  38400  42400  34400  28900\n",
      "  23800    100   2800  41000  16200  19800    200  68400   5600  17800\n",
      "  10100  26000  35000  40400  15400  25600  55900  24600  36900  32600\n",
      "  30800  45300  34900  30700  26600  44500  34100  34800  43200  42100\n",
      "  10500  25700  33400  18800  30000  40200  34300  20700  11300  36500\n",
      "  33500  52600  12800  34500  31100  33300  43800  34700  38100  31300\n",
      "  31400  35400  41200  46700  37400  35200  37900  28300  30500    300\n",
      "  36600  66800  25000  57900  54400  46900  37700  54800  64200  61200\n",
      "  44000  32900  47800  27000  45500  36200  40100  52000  42300  35100\n",
      "  51000  51300  35700  27400  39400  43300  56200  35300  43100  23300\n",
      "  37000  43900  50300  19400  52900  40300  57400  65500  41400  49300\n",
      "  43600  58800  33900  59700  49200  27100  51100  63300  44200  49600\n",
      "  36800  52500  45200  36000  63200  51700  52200  23400  48900  77800\n",
      "  42200  50400  89700 124600  32500  29000  87400  52700  39000  53800\n",
      "  54700  52100  41300  53900  46400  68800  34000  24800  27800  51900\n",
      "  30300  64700  27900  53600  37800  39800  50900  48100  20300  55500\n",
      "  55700  45000  37100  29700  42700  39900  50600  44400  49700  40000\n",
      "  37200  56500  45100  32000 100200  54300  49500  39600  50100  84900\n",
      "  45900  47200  47700  80800  46300  47100  37300  39500  49100]\n",
      "\n",
      "---Duplicados: 10070\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"two_or_more\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"two_or_more\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"two_or_more\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"two_or_more\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be62ab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: hispanic_or_latino\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "10272 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: [  37.  198.   94. ... 1228. 1442. 1830.]\n",
      "\n",
      "---Duplicados: 8094\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"hispanic_or_latino\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"hispanic_or_latino\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"hispanic_or_latino\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"hispanic_or_latino\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fadd7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2 [\"hispanic_or_latino\"]=df2 [\"hispanic_or_latino\"].astype(float) # Trabformar a númerico decimal\n",
    "df2[\"hispanic_or_latino\"] = df2[\"hispanic_or_latino\"].fillna(df2[\"hispanic_or_latino\"].mean()) # Rellenar NaN con la media\n",
    "df2 [\"hispanic_or_latino\"]=df2 [\"hispanic_or_latino\"].astype(int) # Trabformar a númerico entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8a9c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: hispanic_or_latino\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10589 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.9 KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: [  37  198   94 ... 1228 1442 1830]\n",
      "\n",
      "---Duplicados: 8095\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"hispanic_or_latino\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"hispanic_or_latino\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"hispanic_or_latino\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"hispanic_or_latino\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bbe6792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: city\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['Washington' nan 'Auto%#' 'Baltimore' 'Atlanta' 'Oakland' 'New York City']\n",
      "\n",
      "---Duplicados: 10582\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"city\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"city\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"city\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"city\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c133a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"city\"] = df2[\"city\"].bfill()  # rellenar nan con los datos de la fila inferior\n",
    "df2[\"city\"] = df2[\"city\"].where(df2[\"city\"] != 'Auto%#').bfill() #reemplazar Auto%# con los datos de la fila inferior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7d2d88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: city\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10589 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: ['Washington' 'Baltimore' 'Atlanta' 'Oakland' 'New York City']\n",
      "\n",
      "---Duplicados: 10584\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"city\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"city\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"city\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"city\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0a41a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: metro_area\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10272 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 317\n",
      "\n",
      "---Valores unicos: ['Washington-Arlington-Alexandria' nan 'Auto%#'\n",
      " 'Baltimore-Columbia-Towson' 'Atlanta-Sandy Springs-Alpharetta'\n",
      " 'San Francisco-Oakland-Berkeley' 'New York-Newark-Jersey City']\n",
      "\n",
      "---Duplicados: 10582\n"
     ]
    }
   ],
   "source": [
    "# Identificación de los datos\n",
    "df2[\"metro_area\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"metro_area\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"metro_area\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"metro_area\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df1ac9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df2[\"metro_area\"] = df2[\"metro_area\"].bfill()  # rellenar nan con los datos de la fila inferior\n",
    "df2[\"metro_area\"] = df2[\"metro_area\"].where(df2[\"metro_area\"] != 'Auto%#').bfill() #reemplazar Auto%# con los datos de la fila inferior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54d17803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10589 entries, 0 to 10588\n",
      "Series name: metro_area\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10589 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 82.9+ KB\n",
      "\n",
      "---Valores nulos: 0\n",
      "\n",
      "---Valores unicos: ['Washington-Arlington-Alexandria' 'Baltimore-Columbia-Towson'\n",
      " 'Atlanta-Sandy Springs-Alpharetta' 'San Francisco-Oakland-Berkeley'\n",
      " 'New York-Newark-Jersey City']\n",
      "\n",
      "---Duplicados: 10584\n"
     ]
    }
   ],
   "source": [
    "# Verificación de la limpieza\n",
    "df2[\"metro_area\"].info() #caracteristicas de los datos\n",
    "print(f\"\\n---Valores nulos: {df2[\"metro_area\"].isnull().sum()}\") #datos nulos\n",
    "print(f\"\\n---Valores unicos: {df2[\"metro_area\"].unique()}\") #valores unicos\n",
    "print(f\"\\n---Duplicados: {df2.duplicated(subset=[\"metro_area\"]).sum()}\") #Contar duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc13de8",
   "metadata": {},
   "source": [
    "## Diccionarios de traducción.\n",
    "\n",
    "Ahora se procede a la traducción del inglés al español para lograr una mejor interpretación de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "205d61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduccion de columnas\n",
    "traduccion_columnas = {\n",
    "    \"geoid\": \"id_geografico\",\n",
    "    \"name\": \"nombre\",\n",
    "    \"city\": \"ciudad\",\n",
    "    \"metro_area\": \"area_metropolitana\",\n",
    "    \"total_population\": \"poblacion_total\",\n",
    "    \"total_population_25_over\": \"poblacion_mayor_de_25\",\n",
    "    \"median_income\": \"ingreso_medio\",\n",
    "    \"median_home_value\": \"valor_medio_de_vivienda\",\n",
    "    \"white_alone\": \"poblacion_blanca\",\n",
    "    \"black_alone\": \"poblacion_afroamericana\",\n",
    "    \"asian_alone\": \"poblacion_asiatica\",\n",
    "    \"native_alone\": \"poblacion_nativa\",\n",
    "    \"hispanic_or_latino\": \"poblacion_hispana_o_latina\",\n",
    "    \"educational_attainment\": \"educacion\",\n",
    "    \"native_hawaiian_pacific_islander\": \"nativo_hawaiano\", \n",
    "    \"some_other_race_alone\": \"alguna_otra_etnia\",\n",
    "    \"two_or_more\": \"dos_o_mas_etnias\",\n",
    "}\n",
    "df2 = df2.rename(columns=traduccion_columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6024e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traducir ciudades\n",
    "traduccion_ciudades = {\n",
    "    'Washington': \"Washington\", \n",
    "    'Baltimore': 'Baltimore', \n",
    "    'Atlanta': 'Atlanta', \n",
    "    'Oakland': 'Oakland', \n",
    "    'New York City': \"Nueva York\"\n",
    "}\n",
    "\n",
    "df2['ciudad'] = df2['ciudad'].replace(traduccion_ciudades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b18c984f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Washington', 'Baltimore', 'Atlanta', 'Oakland', 'Nueva York'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobaco¿ion de traducción\n",
    "df2['ciudad'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff2166f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Washington-Arlington-Alexandria', 'Baltimore-Columbia-Towson',\n",
       "       'Atlanta-Sandy Springs-Alpharetta',\n",
       "       'San Francisco-Oakland-Berkeley', 'New York-Newark-Jersey City'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobaco¿ion de traducción\n",
    "df2['area_metropolitana'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "606babe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traducir \"Census Tract\" → \"Tracto Censal\"\n",
    "df2[\"nombre\"] = df2[\"nombre\"].str.replace(r'^Census Tract', \"nombre\", regex=True)\n",
    "\n",
    "#Reordenar para que sea: Tracto Censal <número>, Condado de <nombre>, <estado>\n",
    "df2[\"nombre\"] = df2[\"nombre\"].str.replace(\n",
    "    r'^Tracto Censal\\s+([\\d\\.]+),\\s*([\\w\\s\\-]+?) County,\\s*(.+)$',\n",
    "    r'Tracto Censal \\1, Condado de \\2, \\3',\n",
    "    regex=True\n",
    ")\n",
    "\n",
    "#Traducir nombres de estados comunes\n",
    "traduccion_estados = {\n",
    "    'Washington': 'Washington',\n",
    "    'District of Columbia': 'Distrito de Columbia',\n",
    "    \"Maryland\": \"Maryland\",\n",
    "    'Virginia': 'Virginia',\n",
    "    'West Virginia': 'Virginia Occidental',\n",
    "    \"Georgia\": 'Georgia',\n",
    "    'California': 'California',\n",
    "    'New York': 'Nueva York',\n",
    "    'New Jersey': 'Nueva Jersey',\n",
    "    'Connecticut': 'Connecticut',\n",
    "    \n",
    "}\n",
    "\n",
    "for en, es in traduccion_estados.items():\n",
    "    df2['nombre'] = df2['nombre'].str.replace(en, es, regex=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af912c",
   "metadata": {},
   "source": [
    "## Contar duplicados totales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cc7da",
   "metadata": {},
   "source": [
    "Una vez terminado el proceso de rellenado de NaN y sustitucion de datos no coherentes se procede a la identificación y eliminacion de duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9713719a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(752)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identificación de duplicados\n",
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e771bd",
   "metadata": {},
   "source": [
    "Codigo de eliminacion de duuplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adf48ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar duplicados totales\n",
    "df2 = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3101b5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar la correcta eliminacion\n",
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79d49e",
   "metadata": {},
   "source": [
    "## Identificar outliers (datos atipicos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf5719",
   "metadata": {},
   "source": [
    "Identificar los datos atipicos y corregirlos para evitar problemas en futuros analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a4b2805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_geografico</th>\n",
       "      <th>poblacion_total</th>\n",
       "      <th>poblacion_mayor_de_25</th>\n",
       "      <th>ingreso_medio</th>\n",
       "      <th>valor_medio_de_vivienda</th>\n",
       "      <th>educacion</th>\n",
       "      <th>poblacion_blanca</th>\n",
       "      <th>poblacion_afroamericana</th>\n",
       "      <th>poblacion_nativa</th>\n",
       "      <th>poblacion_asiatica</th>\n",
       "      <th>nativo_hawaiano</th>\n",
       "      <th>alguna_otra_etnia</th>\n",
       "      <th>dos_o_mas_etnias</th>\n",
       "      <th>poblacion_hispana_o_latina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.765613e+10</td>\n",
       "      <td>4538.016570</td>\n",
       "      <td>3115.067094</td>\n",
       "      <td>9.959953e+08</td>\n",
       "      <td>2.803804e+09</td>\n",
       "      <td>1.239205e+05</td>\n",
       "      <td>2.076992e+05</td>\n",
       "      <td>915.829725</td>\n",
       "      <td>43.756633</td>\n",
       "      <td>494.253533</td>\n",
       "      <td>514.072176</td>\n",
       "      <td>22.602013</td>\n",
       "      <td>9903.308631</td>\n",
       "      <td>871.394633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.159817e+10</td>\n",
       "      <td>2157.675677</td>\n",
       "      <td>1470.320387</td>\n",
       "      <td>7.921676e+09</td>\n",
       "      <td>1.305490e+10</td>\n",
       "      <td>9.822216e+04</td>\n",
       "      <td>1.776118e+05</td>\n",
       "      <td>1306.817104</td>\n",
       "      <td>162.111363</td>\n",
       "      <td>737.118985</td>\n",
       "      <td>2928.422966</td>\n",
       "      <td>65.695013</td>\n",
       "      <td>10515.445745</td>\n",
       "      <td>1062.886485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.001400e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.400371e+10</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>2134.000000</td>\n",
       "      <td>5.187500e+06</td>\n",
       "      <td>2.668000e+07</td>\n",
       "      <td>5.210000e+04</td>\n",
       "      <td>5.450000e+04</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.402300e+10</td>\n",
       "      <td>4334.000000</td>\n",
       "      <td>2989.000000</td>\n",
       "      <td>7.687500e+06</td>\n",
       "      <td>4.132000e+07</td>\n",
       "      <td>1.049000e+05</td>\n",
       "      <td>1.836000e+05</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.605941e+10</td>\n",
       "      <td>5675.000000</td>\n",
       "      <td>3886.000000</td>\n",
       "      <td>1.089130e+07</td>\n",
       "      <td>6.574000e+07</td>\n",
       "      <td>1.695000e+05</td>\n",
       "      <td>3.129000e+05</td>\n",
       "      <td>1229.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>1047.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.403797e+10</td>\n",
       "      <td>28937.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>6.666667e+10</td>\n",
       "      <td>6.666667e+10</td>\n",
       "      <td>1.054200e+06</td>\n",
       "      <td>1.565700e+06</td>\n",
       "      <td>16655.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>7822.000000</td>\n",
       "      <td>89200.000000</td>\n",
       "      <td>1325.000000</td>\n",
       "      <td>124600.000000</td>\n",
       "      <td>12424.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_geografico  poblacion_total  poblacion_mayor_de_25  ingreso_medio  \\\n",
       "count   9.837000e+03      9837.000000            9837.000000   9.837000e+03   \n",
       "mean    2.765613e+10      4538.016570            3115.067094   9.959953e+08   \n",
       "std     1.159817e+10      2157.675677            1470.320387   7.921676e+09   \n",
       "min     6.001400e+09         0.000000               0.000000   0.000000e+00   \n",
       "25%     2.400371e+10      3101.000000            2134.000000   5.187500e+06   \n",
       "50%     3.402300e+10      4334.000000            2989.000000   7.687500e+06   \n",
       "75%     3.605941e+10      5675.000000            3886.000000   1.089130e+07   \n",
       "max     5.403797e+10     28937.000000           21613.000000   6.666667e+10   \n",
       "\n",
       "       valor_medio_de_vivienda     educacion  poblacion_blanca  \\\n",
       "count             9.837000e+03  9.837000e+03      9.837000e+03   \n",
       "mean              2.803804e+09  1.239205e+05      2.076992e+05   \n",
       "std               1.305490e+10  9.822216e+04      1.776118e+05   \n",
       "min               0.000000e+00  0.000000e+00      0.000000e+00   \n",
       "25%               2.668000e+07  5.210000e+04      5.450000e+04   \n",
       "50%               4.132000e+07  1.049000e+05      1.836000e+05   \n",
       "75%               6.574000e+07  1.695000e+05      3.129000e+05   \n",
       "max               6.666667e+10  1.054200e+06      1.565700e+06   \n",
       "\n",
       "       poblacion_afroamericana  poblacion_nativa  poblacion_asiatica  \\\n",
       "count              9837.000000       9837.000000         9837.000000   \n",
       "mean                915.829725         43.756633          494.253533   \n",
       "std                1306.817104        162.111363          737.118985   \n",
       "min                   0.000000          0.000000            0.000000   \n",
       "25%                  82.000000          0.000000           64.000000   \n",
       "50%                 374.000000          0.000000          232.000000   \n",
       "75%                1229.000000         17.000000          582.000000   \n",
       "max               16655.000000        910.000000         7822.000000   \n",
       "\n",
       "       nativo_hawaiano  alguna_otra_etnia  dos_o_mas_etnias  \\\n",
       "count      9837.000000        9837.000000       9837.000000   \n",
       "mean        514.072176          22.602013       9903.308631   \n",
       "std        2928.422966          65.695013      10515.445745   \n",
       "min           0.000000           0.000000          0.000000   \n",
       "25%           0.000000           0.000000       2400.000000   \n",
       "50%           0.000000           0.000000       7000.000000   \n",
       "75%           0.000000          22.000000      13600.000000   \n",
       "max       89200.000000        1325.000000     124600.000000   \n",
       "\n",
       "       poblacion_hispana_o_latina  \n",
       "count                 9837.000000  \n",
       "mean                   871.394633  \n",
       "std                   1062.886485  \n",
       "min                      0.000000  \n",
       "25%                    214.000000  \n",
       "50%                    491.000000  \n",
       "75%                   1047.000000  \n",
       "max                  12424.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identificar columnas numericas\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5fe62ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identificar outliers\n",
    "\n",
    "# Inicializar máscara\n",
    "outlier_mask = pd.DataFrame(False, index=df2.index, columns=df2.columns)\n",
    "\n",
    "# Aplicar IQR por columna numérica\n",
    "for col in df2.select_dtypes(include='number'):\n",
    "    Q1 = df2[col].quantile(0.25)\n",
    "    Q3 = df2[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outlier_mask[col] = (df2[col] < lower_bound) | (df2[col] > upper_bound)\n",
    "\n",
    "# Filtrar filas con al menos un outlier\n",
    "df_outliers = df2[outlier_mask.any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04144019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descartar outliers\n",
    "\n",
    "\n",
    "df_corr = df2.copy()\n",
    "\n",
    "# Iterar sobre columnas numéricas\n",
    "for col in df_corr.select_dtypes(include='number'):\n",
    "    Q1 = df_corr[col].quantile(0.25)\n",
    "    Q3 = df_corr[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Detectar outliers\n",
    "    outliers = (df_corr[col] < lower_bound) | (df_corr[col] > upper_bound)\n",
    "\n",
    "    # Reemplazar outliers por la mediana\n",
    "    df_corr.loc[outliers, col] = df_corr[col].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eafb6a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_geografico</th>\n",
       "      <th>poblacion_total</th>\n",
       "      <th>poblacion_mayor_de_25</th>\n",
       "      <th>ingreso_medio</th>\n",
       "      <th>valor_medio_de_vivienda</th>\n",
       "      <th>educacion</th>\n",
       "      <th>poblacion_blanca</th>\n",
       "      <th>poblacion_afroamericana</th>\n",
       "      <th>poblacion_nativa</th>\n",
       "      <th>poblacion_asiatica</th>\n",
       "      <th>nativo_hawaiano</th>\n",
       "      <th>alguna_otra_etnia</th>\n",
       "      <th>dos_o_mas_etnias</th>\n",
       "      <th>poblacion_hispana_o_latina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9.837000e+03</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.0</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "      <td>9837.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.765613e+10</td>\n",
       "      <td>4363.817526</td>\n",
       "      <td>2997.536241</td>\n",
       "      <td>7.775926e+06</td>\n",
       "      <td>4.272113e+07</td>\n",
       "      <td>113151.364034</td>\n",
       "      <td>200254.060791</td>\n",
       "      <td>610.492122</td>\n",
       "      <td>4.716275</td>\n",
       "      <td>301.964623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.970418</td>\n",
       "      <td>8160.633018</td>\n",
       "      <td>585.060181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.159817e+10</td>\n",
       "      <td>1802.571114</td>\n",
       "      <td>1235.195843</td>\n",
       "      <td>3.663633e+06</td>\n",
       "      <td>2.364927e+07</td>\n",
       "      <td>76898.119916</td>\n",
       "      <td>162728.233349</td>\n",
       "      <td>710.335922</td>\n",
       "      <td>9.360484</td>\n",
       "      <td>309.495557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.331015</td>\n",
       "      <td>7148.485568</td>\n",
       "      <td>501.113034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.001400e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.400371e+10</td>\n",
       "      <td>3101.000000</td>\n",
       "      <td>2134.000000</td>\n",
       "      <td>5.187500e+06</td>\n",
       "      <td>2.668000e+07</td>\n",
       "      <td>52100.000000</td>\n",
       "      <td>54500.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.402300e+10</td>\n",
       "      <td>4334.000000</td>\n",
       "      <td>2989.000000</td>\n",
       "      <td>7.687500e+06</td>\n",
       "      <td>4.132000e+07</td>\n",
       "      <td>104900.000000</td>\n",
       "      <td>183600.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.605941e+10</td>\n",
       "      <td>5496.000000</td>\n",
       "      <td>3758.000000</td>\n",
       "      <td>9.958300e+06</td>\n",
       "      <td>5.374000e+07</td>\n",
       "      <td>158600.000000</td>\n",
       "      <td>305400.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11800.000000</td>\n",
       "      <td>827.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.403797e+10</td>\n",
       "      <td>9513.000000</td>\n",
       "      <td>6514.000000</td>\n",
       "      <td>1.944170e+07</td>\n",
       "      <td>1.242700e+08</td>\n",
       "      <td>345400.000000</td>\n",
       "      <td>699000.000000</td>\n",
       "      <td>2947.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1358.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>30400.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_geografico  poblacion_total  poblacion_mayor_de_25  ingreso_medio  \\\n",
       "count   9.837000e+03      9837.000000            9837.000000   9.837000e+03   \n",
       "mean    2.765613e+10      4363.817526            2997.536241   7.775926e+06   \n",
       "std     1.159817e+10      1802.571114            1235.195843   3.663633e+06   \n",
       "min     6.001400e+09         0.000000               0.000000   0.000000e+00   \n",
       "25%     2.400371e+10      3101.000000            2134.000000   5.187500e+06   \n",
       "50%     3.402300e+10      4334.000000            2989.000000   7.687500e+06   \n",
       "75%     3.605941e+10      5496.000000            3758.000000   9.958300e+06   \n",
       "max     5.403797e+10      9513.000000            6514.000000   1.944170e+07   \n",
       "\n",
       "       valor_medio_de_vivienda      educacion  poblacion_blanca  \\\n",
       "count             9.837000e+03    9837.000000       9837.000000   \n",
       "mean              4.272113e+07  113151.364034     200254.060791   \n",
       "std               2.364927e+07   76898.119916     162728.233349   \n",
       "min               0.000000e+00       0.000000          0.000000   \n",
       "25%               2.668000e+07   52100.000000      54500.000000   \n",
       "50%               4.132000e+07  104900.000000     183600.000000   \n",
       "75%               5.374000e+07  158600.000000     305400.000000   \n",
       "max               1.242700e+08  345400.000000     699000.000000   \n",
       "\n",
       "       poblacion_afroamericana  poblacion_nativa  poblacion_asiatica  \\\n",
       "count              9837.000000       9837.000000         9837.000000   \n",
       "mean                610.492122          4.716275          301.964623   \n",
       "std                 710.335922          9.360484          309.495557   \n",
       "min                   0.000000          0.000000            0.000000   \n",
       "25%                  82.000000          0.000000           64.000000   \n",
       "50%                 374.000000          0.000000          232.000000   \n",
       "75%                 910.000000          5.000000          457.000000   \n",
       "max                2947.000000         42.000000         1358.000000   \n",
       "\n",
       "       nativo_hawaiano  alguna_otra_etnia  dos_o_mas_etnias  \\\n",
       "count           9837.0        9837.000000       9837.000000   \n",
       "mean               0.0           6.970418       8160.633018   \n",
       "std                0.0          12.331015       7148.485568   \n",
       "min                0.0           0.000000          0.000000   \n",
       "25%                0.0           0.000000       2400.000000   \n",
       "50%                0.0           0.000000       7000.000000   \n",
       "75%                0.0          11.000000      11800.000000   \n",
       "max                0.0          55.000000      30400.000000   \n",
       "\n",
       "       poblacion_hispana_o_latina  \n",
       "count                 9837.000000  \n",
       "mean                   585.060181  \n",
       "std                    501.113034  \n",
       "min                      0.000000  \n",
       "25%                    214.000000  \n",
       "50%                    491.000000  \n",
       "75%                    827.000000  \n",
       "max                   2295.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar la estandarizacion de los outliers\n",
    "\n",
    "df_corr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b20e2d",
   "metadata": {},
   "source": [
    "# Verificar la limpieza de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364489b",
   "metadata": {},
   "source": [
    "Ya que se han realizado los pasos anteriores, verificar datos nulos, conversion de datos (de string a float y de float a entero), identificación y corrección de datos no coherentes, traducción de textos, cambios de nombres a columnas, detectar y corregir duplicados y finalmente identificar y estandarizar outliers, se procede a verificar que todo se ha llevado a cabao correctamente y que la base esta realmente limpia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca164185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9837 entries, 0 to 10588\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   id_geografico               9837 non-null   int64 \n",
      " 1   nombre                      9837 non-null   object\n",
      " 2   poblacion_total             9837 non-null   int64 \n",
      " 3   poblacion_mayor_de_25       9837 non-null   int64 \n",
      " 4   ingreso_medio               9837 non-null   int64 \n",
      " 5   valor_medio_de_vivienda     9837 non-null   int64 \n",
      " 6   educacion                   9837 non-null   int64 \n",
      " 7   poblacion_blanca            9837 non-null   int64 \n",
      " 8   poblacion_afroamericana     9837 non-null   int64 \n",
      " 9   poblacion_nativa            9837 non-null   int64 \n",
      " 10  poblacion_asiatica          9837 non-null   int64 \n",
      " 11  nativo_hawaiano             9837 non-null   int64 \n",
      " 12  alguna_otra_etnia           9837 non-null   int64 \n",
      " 13  dos_o_mas_etnias            9837 non-null   int64 \n",
      " 14  poblacion_hispana_o_latina  9837 non-null   int64 \n",
      " 15  ciudad                      9837 non-null   object\n",
      " 16  area_metropolitana          9837 non-null   object\n",
      "dtypes: int64(14), object(3)\n",
      "memory usage: 1.4+ MB\n",
      "\n",
      "---Datos nulos restantes: \n",
      "id_geografico                 0\n",
      "nombre                        0\n",
      "poblacion_total               0\n",
      "poblacion_mayor_de_25         0\n",
      "ingreso_medio                 0\n",
      "valor_medio_de_vivienda       0\n",
      "educacion                     0\n",
      "poblacion_blanca              0\n",
      "poblacion_afroamericana       0\n",
      "poblacion_nativa              0\n",
      "poblacion_asiatica            0\n",
      "nativo_hawaiano               0\n",
      "alguna_otra_etnia             0\n",
      "dos_o_mas_etnias              0\n",
      "poblacion_hispana_o_latina    0\n",
      "ciudad                        0\n",
      "area_metropolitana            0\n",
      "dtype: int64\n",
      "\n",
      "---Duplicados restantes: \n",
      "663\n"
     ]
    }
   ],
   "source": [
    "# Verificar columnas totales restantes\n",
    "\n",
    "df2.info()\n",
    "\n",
    "#Verificar el total de valores nulos\n",
    "print(f\"\\n---Datos nulos restantes: \\n{df2.isnull().sum()}\") \n",
    "\n",
    "#Verificar el total de duplicados\n",
    "print(f\"\\n---Duplicados restantes: \\n{df.duplicated().sum()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84fda2",
   "metadata": {},
   "source": [
    "## Se ha logrado la limpieza exitosa de la base de datos\n",
    "\n",
    "Por lo tanto se procede a la creacion de un nuevo archivo csv con la base limpia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb67e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar los resultados en un csv\n",
    "df.to_csv(\"Census_tracts_limpios.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
